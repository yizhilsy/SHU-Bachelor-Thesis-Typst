#import "../lib.typ": documentclass, algox, tablex

#let (
  info,
  doc,
  cover,
  declare,
  appendix,
  outline,
  mainmatter,
  conclusion,
  abstract,
  bib,
  acknowledgement,
  under-cover,
) = documentclass(
  info: (
    title: "多模态表征的非线形相关性研究",
    school: "计算机工程与科学学院",
    major: "计算机科学与技术",
    student_id: "21121889",
    name: "陆诗雨",
    supervisor: "王含章",
    date: "2024.12-2025.5",
  ),
)

#show: doc
#cover()
#declare()

#abstract(
  keywords: ("多模态模型", "非线形相关性", "模态融合", "评估模态对齐"),
  keywords-en: ("multimodal model", "nolinear correlation", "modality interface", "eval alignment"),
)[
  摘要的内容需作者简要介绍本论文的主要内容主要为本人所完成的工作和创新点。

  ……

  (注：标题黑体小二号，正文宋体小四，行距20磅)
][
  The content of the abstract requires the author to briefly introduce the main content of this paper, mainly for my work and innovation.

  …….

  (Times New Roman，小四号，行距20磅)
]

#outline()

#show: mainmatter
= 绪论

== 研究背景及意义
在人类社会及科技发展的过程中，对于多个模态信息的呈现、处理和理解需求一直存在。早期人们希望可以实现多媒体传播来传递例如视频、图像、文本等信息，这促进了互联网技术和多媒体技术的发展。随着近年来人工智能技术的快速发展，人们希望构建一种通用的智能体来处理并帮助理解多个模态之间的信息，例如根据输入的描述从视频中提取关键帧，根据上传的图像及问题生成相应的回答，亦或是根据描述快速地从海量数据中检索出感兴趣的图像等。这促进了人们对于多模态研究的关注程度，多模态研究的重要程度在于提供了一种高效准确的多信息处理方式以及构建通用人工智能的能力，这也是人工智能发展的核心愿景。

早期研究者设计的多模态模型主要适用于特定领域的任务，例如图文检索，图片字幕描述，视觉语言问答等任务，以这些任务为代表涌现了一批优秀的多模态模型，例如Stacked Cross Attention @lee2018stacked，Neural Image Caption @vinyals2015show，Multimodal Compact Bilinear Pooling @fukui2016mcb 等模型。然而这些模型在设计和训练时往往引入了特定任务的限定，使得模型的能力仅能专注于特定的任务，对于其他的任务适应能力差。这使得多模态领域的技术局限在有限的应用场景中，并催发人们致力于构建一个统一的泛化能力强的多模态模型的强烈兴趣。

近年来随着算力的提升和数据集数量的增加，模型朝着大规模的方向发展。通过扩展模型参数量和训练数据量，在大型语言模型（LLM）和大型视觉模型（LVM）领域有了显著的进展。大型语言模型在文本生成（Text Generation），文本理解（In-Context Learning），指令跟随(Instruct Following)等任务上的能力呈现出了优异的水平；大型视觉模型在目标检测（Object Detection），图像分割（Image Segmentation），图像分类（Image Classification）等任务上也表现出了令人印象深刻的性能。随着大模型在各自模态中的成功，研究者们开始关注在多模态领域中的进一步研究，多模态模型的正式定义是指*具有同时处理和理解多种模态（如文本、图像等模态）的信息的能力，并且进一步可以完成多模态任务如图文检索（Iamge-Text Retrieval），视觉问答（Visual Qusetion Answer）的模型*。大型语言模型在指令跟随及文本理解上的强大性能显示了文本作为通用任务指令的接口的可行性，借助预训练大型语言模型出色的零样本及少样本能力，可以帮助模型更好地建模不同模态间的语义关联，因此研究者们开始关注以大型语言模型为基础的多模态模型的研究。一个直接且作为当前主流的思路是应用在各自模态中取得显著性能的大模型，*然而，如何有效地将不同模态的信息进行融合并且让多模态模型准确地理解来自不同模态的信息来完成多模态任务是多模态领域中的关键问题*。

研究者们在近年来提出了多种基于大型语言模型的多模态模型以及相关的多模态融合方法。值得注意的是，无论是在设计多模态模型的网络还是在设计多模态模型的预训练任务上，研究者们都强调了多模态对齐的重要性。在ALBEF @li2021alignfusevisionlanguage 的工作中，研究者从理论分析出发，借助多模态互信息下限最大化的角度揭示了模态对齐的价值和重要性。同样的，ALBEF在网络设计上也引入了图文对比学习的网络来实现模态对齐的目标。类似的，在LLaVA @llava 的工作中，研究者将训练步骤拆分为了两个阶段，第一阶段在大量的图文描述对上进行训练，目标也是模态对齐。

然而，虽然研究者们都肯定了多模态大模型模态对齐的价值，但现有的研究未针对模态对齐融合的质量进行详细的研究，研究者们往往通过经验的方式或是设计相关的预训练任务（如图文对比学习任务等）来粗略地考虑是否对齐，*缺乏一个客观的易于计算的评估指标来反映模型在训练阶段时不同时刻模态对齐融合的质量*，从而指导模态对齐融合网络的训练，设计并以此提升模态对齐融合的质量和多模态大语言模型在下游任务上的性能。

在深度神经网络的可解释性领域，为了衡量两个神经网络是否相似，研究者们借助计算由两个神经网络产生的不同数据潜在表征之间的统计相关性来衡量相似性 @nguyen2021do 。本文受到这种方法的启发，通过计算不同模态的数据（主要是图像-文本对的数据）在多模态大语言模型中产生的数据表征间的统计相关性来衡量多模态大语言模型的模态对齐程度（能力）。然而这些多模态表征在如今的多模态大模型中不仅是高维的，且互相存在复杂的非线形关系，利用传统的线形相关性及非线形相关性计算方法如CCA @cca ， SVCCA @svcca ， CKA @cka ，dCor @dcor1 @dcor2 等都不能准确有效地衡量相关性。幸运的是，最近在idcor @basile2024intrinsic 的工作中提出的idcor计算指标在衡量表征之间的相关性上表现出了远超传统方法的性能， 尤其是在多模态表征领域。它利用了归一化互信息，但使用了表征的本征维度来代替表征的熵，使用低维数据集中可以恢复的在高维数据集中自变量的比例衡量了相关性。由于idcor衡量指标在多模态表征上的出色表现，本文基于idcor指标，提出了可以用于评估多模态大模型的模态对齐质量的评估算法，且提出了可适用于庞大评估模态对齐数据集的分组计算期望算法。并在近年来主流的开源多模态大模型上进行了实验验证证明其合理性。

本文希望本文提出的多模态表征的非线性相关性评估算法可以帮助更准确严谨地衡量多模态大模型模态对齐的性能。此外本文也注意到多模态表征的非线性相关性指标可以进一步帮助模态对齐融合网络的设计与训练过程，并有助于多模态大语言模型在下游任务上微调后的性能；同时多模态表征的非线性相关性指标还有可能有助于构建高质量多模态数据集。本文也针对多模态表征的非线形相关性指标可能带来的应用进行了比较详实的实验探索。本文的研究以期进一步推动多模态大语言模型的发展。

== 相关研究现状

=== 多模态模型的模态融合方式发展历程

在多模态领域的研究历史中，研究者们倾向于首先为每个模态选取一个表现优异的单模态模型，这些单模态模型往往是预训练好的，而将研究的主要工作放在设计不同种模态表征之间的融合方式上。多模态领域的早期工作中，融合不同模态的表征采取了简单直接的方式 @vinyals2015show @Lu2015。以视觉-语言的多模态模型为例，在Neural Image Caption @vinyals2015show 的工作中，图像表征由图像在卷积神经网络（CNN）的最后一层隐藏层得到，并直接送入循环神经网络（RNN）的decoder中进行图像描述生成；在Deeper LSTM and normalized CNN @Lu2015 的工作中，对由卷积神经网络得到的图像嵌入向量和由长短期记忆网络（LSTM）得到的问题文本的嵌入向量进行逐点相乘，得到一个新的向量作为图像和文本的融合表征并在之后送入多层分类器去预测词语的概率分布。简单直接的模态表征融合无法捕捉不同模态表征间深层次的语义关系，且受限于早期的单模态模型的性能，这些方法的性能有限，同时模型往往是为了特定的任务而设计并训练的，缺乏泛化到多种任务上的能力。

之后的研究随着新的优秀的单模态模型的提出，尤其是在目标检测领域及自然语言处理领域取得成功的模型，同时随着注意力机制 @vaswani2017attention 及多模态领域中交叉注意力机制理论@NEURIPS2019_c74d97b0 的成熟与推广，研究者们基于新的单模态模型提出了更为复杂的基于注意力机制的模态融合方法。例如在LXMERT @tan2019lxmertlearningcrossmodalityencoder 的工作中，图像模态的表征由目标检测模型检测到的物体的区域感兴趣特征及位置信息特征得到，并在之后与文本模态的表征进行交叉注意力机制的融合。然而，这种模态融合方法并没有将不同模态的表征映射进同一个维度空间中进行融合，这对于模型捕获到不同模态表征间的语义关联造成了阻碍；同时目标检测的视觉模型在预训练和推理时的计算资源消耗较大 @li2021alignfusevisionlanguage。

近年来大型语言模型在自然语言处理领域中取得了一系列成功，如：ChatGPT @ChatGPT 和GPT-4 @GPT4 等模型，大型语言模型为研究者展现了其卓越的指令跟随及文本理解能力。得益于预训练大型语言模型的开源，如LLaMA @touvron2023llamaopenefficientfoundation
 , Vicuna @vicuna2023 , Qwen @bai2023qwentechnicalreport 等，使得在多模态研究中构建以大型语言模型为中心的多模态模型成为可能。这是因为可以利用文本作为通用任务指令的接口得以让模型可以训练并理解多种不同的复杂任务，同时借助预训练大型语言模型出色的语言理解和指令跟随能力，这使得构建通用的可以泛化到多种不同多模态任务的模型变成了可能。目前，以大模型为基础的多模态模型主要有三种模态融合的方式：分别是以LLaVA @llava 为代表的直接投影法，以BLIP-2 @blip2 为代表的基于Attention架构的Q-Former方法，以及以Flamingo @flamingo 为代表的在大型语言模型内部插入额外参数模块以实现文本特征和视觉特征的交互融合，从而将视觉信息注入到文本的生成过程中的特征极板块融合法。

从多模态模型的发展历程中可以看出，多模态模型的研究重点主要在于模态融合的方式上。值得提出的是，近年来以大型预训练语言模型为中心的多模态大模型的研究倾向于冻结部分或全部视觉模型和文本模型的参数，专注于训练模态融合的网络参数；同时在大型语言模型的指令微调技术也应用到了多模态大模型当中 @llava @instructblip 。模态融合方式直接影响了多模态模型能否建模不同模态间复杂的语义，进一步呼吁了设计合理高效的模态融合网络及评估算法的需求。

=== 潜在空间表征相关性衡量指标研究现状
在神经网络的可解释性领域，一个研究的关键点是试图判断两个不同的神经网络是否可以在相同的数据集上学习到相似的方式去处理数据。虽然定义两个神经网络具有相似的行为存在一定的困难和歧义，但在最近几年研究者们从神经网络学习到的表征之间的统计相关性入手，取得了重大的进展。基于表征学习和统计相关性，研究者们已经提出了许多线形及非线形的可用于衡量表征间相关性的指标，如Singular Value Canonical Correlation Analysis (SVCCA) @svcca ，Centered Kernel Alignment （CKA） @cka，Distance Correlation（dCor）@dcor1 @dcor2，Canonical Correlation Analysis（CCA） @cca 等。这些技术已被广泛用于更深入地了解神经模型处理信息方式的各个方面。

然而，上述指标存在一些局限性。例如Canonical Correlation Analysis（CCA）主要从线形相关的角度出发去衡量表征之间的相关性，但在实际情况下，不同的表征之间往往存在复杂的非线形关系；从表征的数据点之间的距离出发的Distance Correlation（dCor）指标虽然能够捕获一定的非线形关系，但是在高维的表征上表现不佳 @basile2024intrinsic；从硬件要求的角度出发，Centered Kernel Alignment （CKA）在计算大规模数据集上得到的表征时需要消耗过高的显存及计算资源，且计算复杂度较高。在如今的多模态模型朝着大规模，使用大型语言模型的趋势下，现有的表征相关性指标在衡量多模态大模型产生的大量高维，彼此间由不同模态的模型产生的表征时的性能不甚理想。

在最近的研究中，Lorenzo @basile2024intrinsic 等人提出了一种新的衡量表征之间的相关性的方法，称为Intrinsic Distance Correlation（idcor）。该方法使用了归一化互信息，但使用了表征的本征维度来代替表征的熵，并使用低维数据集中可以恢复的在高维数据集中自变量的比例来衡量相关性。该指标在高维非线形的表征上相比之前的几种指标表现出了更好的性能，此外在多模态数据集上也具有强大的能力去衡量不同模态的模型产生的表征之间的相关性（例如图文模型在MSCOCO @mscoco2014 数据集上产生的表征之间的相关性），相比原先的基线指标dCor具有大幅的性能领先。同时，idcor指标的计算代价主要来自计算表征集合的本征维度。而运用TwoNN @twoNN 来计算本征维度已被大量的工作证实具有高效性 @NEURIPS2019_cfcce062 ，且TwoNN在大规模数据上的表征点的高维空间密度高度不均匀时也能表现出良好的性能。因此idcor指标的计算资源代价也是优秀的。

然而，在Intrinsic Distance Correlation（idcor） 的工作中却尚未将此指标应用于近年来主流的开源多模态大模型产生的不同模态的表征评估上，仅针对一些早期的视觉及文本模态模型如ResNet-18 @resnet ，EfficientNet @efficientnet ， VIT @vit ，Bert @bert ，ALBERT @albert ，Electra @electra 及CLIP @clip 下属的单模态模型上进行了多模态表征相关性的实验 @basile2024intrinsic。这也是本文的研究动机之一。本文希望借助idcor指标的优越性能，设计出一个可以用于评估多模态大模型模态对齐质量的高效评估算法，并在主流的多模态大模型上进行实验验证。

=== 多模态潜在空间对齐的理论研究现状
在Luca Moschella @moschellarelative 等人的工作中经验性地揭示了如果多模态的数据存在某种语义对齐（例如图像及其对应的描述），那么就可以在潜在空间中传递知识。这种知识传递的可行性由原始表征的每个点与一组固定的锚点之间的距离所代表的相对表征来实现。Luca Moschella等人还表明使用这种相对表征，可以不需要额外训练的情况下，将来自不同模态的模型的编码器和解码器拼接在一起 @basile2024intrinsic。

同时也有研究表明 @pmlr-v202-moayeri23a ，当对对齐数据（即相同的数据或共享某些语义的多模态数据，例如图像-标题对）进行评估时，大型最先进的视觉和文本编码器可以产生可转移的表示。事实上，一个简单的线性变换通常就足以将一个潜在空间映射到另一个潜在空间。从而实现借助另一个模态的表征来完成对应的下游任务例如分类等。

在语义对齐的多模态数据上存在的多模态潜在空间的相关性可以用于建模不同模态间深层次的语义关系。如果存在一个不依赖任何下游任务评估的情况下检测这些相关性的指标，那么可以用于帮助研究者衡量模型模态对齐程度，以便及时做出调整更好的让模型建模不同模态之间的语义。

== 本文研究内容
在多模态领域的研究中，设计一个高效的模态融合网络一直是一个重要的研究方向。在很多研究者的工作中，如Junnan Li @li2021alignfusevisionlanguage @blip2， Haotian Liu @llava 等人，都从模态融合网络的设计或是多模态预训练任务的角度上出发来保证模态融合网络的模态对齐性能。在一些研究中，如Haotian Liu @llava 等人通过消融的实验方式证实了缺乏模态对齐的训练步骤会对多模态模型的性能造成显著的下降。尽管现有的研究都在关注模态对齐的重要性，但现有的研究往往缺乏一个客观的评估指标来衡量模态对齐的质量亦或是观察多模态模型在训练过程中模态对齐程度的变化。研究者们同样也只能从多模态模型在下游任务上的性能来间接地推测设计的模态融合网络是否合理。并不利于多模态模型的进一步设计与优化。

针对以上提到的这些问题，本文的研究内容如下：
1. 研究内容一：广泛收集现有的主流多模态大语言模型的设计架构的文献（如BLIP-2 @blip2，LLaVA @llava，Flamingo @flamingo 等），理解分析主流架构在模型设计尤其是多模态表征对齐融合网络设计上的思路并捋清发展历程。分析各种多模态表征对齐融合网络的优劣和特点。

2. 研究内容二：研究多模态表征的非线性相关性，提出一个客观准确的，计算高效的评估相关性算法，并通过多角度的实验（如在高维、强非线形、线形数据集、现实多模态数据集上验证）与其他计算多模态表征的相关性的指标进行对比，分析其优劣，得到一个最佳的计算多模态表征之间的非线性相关性的算法。

3. 研究内容三：借助研究内容二得到的指标衡量不同的多模态大语言模型（可能是不同的多模态大语言模型也可能是同一个多模态大语言模型的不同训练阶段）在模态对齐上的程度。设计实验研究模态对齐融合的程度将如何影响模型在后续下游任务上的性能。下游任务上的性能将借助现有的研究广泛采用的一些benchmark基准测试，如ScienceQA等来进行评估。

4. 研究内容四：初步探索如何借助研究内容二得到的指标指导模态对齐融合网络的设计，训练及过滤高质量多模态数据集。

== 本文组织架构
之后再写吧


= 评估多模态表征的相关性

== 在人造的数据表征上评估

== 在神经网络上评估

== 在单一模态（视觉）表征上进行评估

== 在多模态表征（图文）上进行评估

=== MSCOCO

=== N24News



=== 三级标题

......

==== 四级标题

......

== 本文研究主要内容

本文......

== 本文研究意义

本文......

== 本文组织架构

本文......

= 格式要求


正文各章节应拟标题，每章结束后应另起一页。标题要简明扼要，不应使用标点符号。各章、节、条的层次，可以按照“1……、1.1……、1.1.1……”标识，条以下具体款项的层次依次按照“1.1.1.1”或“（1）”、“①”等标识。各学院根据实际情况，可自行规定层次格式，但学院之内建议格式统一，以清晰无误为准@liu_survey_2024。

正文是毕业论文的主体和核心部分，不同学科专业和不同的选题可以有不同的写作方式。正文一般包括以下几个方面。

== 引言或背景
引言是论文正文的开端，引言应包括毕业论文选题的背景、目的和意义；对国内外研究现状和相关领域中已有的研究成果的简要评述；介绍本项研究工作研究设想、研究方法或实验设计、理论依据或实验基础；涉及范围和预期结果等。要求言简意赅，注意不要与摘要雷同或成为摘要的注解。

== 主体
论文主体是毕业论文的主要部分，必须言之成理，论据可靠，严格遵循本学科国际通行的学术规范。在写作上要注意结构合理、层次分明、重点突出，章节标题、公式图表符号必须规范统一。论文主体的内容根据不同学科有不同的特点，一般应包括以下几个方面：
+ 毕业设计（论文）总体方案或选题的论证；
+ 毕业设计（论文）各部分的设计实现，包括实验数据的获取、数据可行性及有效性的处理与分析、各部分的设计计算等；
+ 对研究内容及成果的客观阐述，包括理论依据、创新见解、创造性成果及其改进与实际应用价值等；
+ 论文主体的所有数据必须真实可靠，自然科学论文应推理正确、结论清晰；人文和社会学科的论文应把握论点正确、论证充分、论据可靠，恰当运用系统分析和比较研究的方法进行模型或方案设计，注重实证研究和案例分析，根据分析结果提出建议和改进措施等。

== 结论
结论是毕业论文的总结，是整篇论文的归宿。应精炼、准确、完整。着重阐述自己的创造性成果及其在本研究领域中的意义、作用，还可进一步提出需要讨论的问题和建议。

= 相关工作

= 图表格式

== 图格式
#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image>

#v(1.5em)

// 图的引用请以 img 开头
如 @img:image 所示，......

== 表格格式
// 表的引用请以 tbl 开头
我们来看 @tbl:table，

可以续表:
\
\
\

#tablex(
  ..for i in range(15) {
    ([250], [88], [5900], [1.65])
  },
  header: (
    [感应频率 #linebreak() (kHz)],
    [感应发生器功率 #linebreak() (%×80kW)],
    [工件移动速度 #linebreak() (mm/min)],
    [感应圈与零件间隙 #linebreak() (mm)],
  ),
  columns: (1fr, 1fr, 1fr, 1fr),
  colnum: 4,
  caption: [66666666],
  label-name: "table",
)


== 公式格式

// 公式的引用请以 eqt 开头
我要引用 @eqt:equation。

$ 1 / mu nabla^2 Alpha - j omega sigma Alpha - nabla(1/mu) times (nabla times Alpha) + J_0 = 0 $<equation>

== 算法格式
我要引用 @algo:algorithm

算法也可以续：
#v(10em)
#[
  #import "@preview/lovelace:0.2.0": *
  #algox(
    label-name: "algorithm",
    caption: [欧几里得辗转相除],
    pseudocode(
      no-number,
      [#h(-1.25em) *input:* integers $a$ and $b$],
      no-number,
      [#h(-1.25em) *output:* greatest common divisor of $a$ and $b$],
      [*while* $a != b$ *do*],
      ind,
      [*if* $a > b$ *then*],
      ind,
      $a <- a - b$,
      ded,
      [*else*],
      ind,
      $b <- b - a$,
      ded,
      [*end*],
      ded,
      [*end*],
      [*return* $a$],
    ),
  )
]

也可以直接插入代码：
#algox(
  label-name: "algorithm-1",
  caption: [欧几里得辗转相除C++实现],
  [
    ```cpp
    #include <bits/stdc++.h>
    using namespace std;
    int gcd(int a, int b) {
      while (a != b) {
        if (a > b) a -= b;
        else b -= a;
      }
      return a;
    }
    ```
  ],
)

== 本章小结

本章介绍了……

#conclusion[
  结论是毕业论文的总结，是整篇论文的归宿。应精炼、准确、完整。着重阐述自己的创造性成果及其在本研究领域中的意义、作用，还可进一步提出需要讨论的问题和建议。
]

// 参考文献
#bib(bibfunc: bibliography("ref.bib")) // full: false 表示只显示已引用的文献，不显示未引用的文献；true 表示显示所有文献

#show: appendix

= 附录格式

论文附录依次用大写字母“附录A、附录B、附录C……”表示，附录内的分级序号可采用“附A1、附A1.1、附A1.1.1”等表示，图、表、公式均依此类推为“图A1、表A1、式（A1）”等。包含以下内容：

（1）代码、图表、标准、手册等数据；

（2）未发表过的一手文献；

（3）公式推导与证明、调查表等；

（4）辅助性教学工具或表格；

（5）其他需要展示或说明的内容

……

（标题黑体小二号，内容Times New Roman/宋体，小四号，行距20磅）

== 测试1

#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image2>
......

=== 测试1.1

#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image3>

= 测试2
#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image4>

......

#acknowledgement(location: "上海大学")[
  表达真情实感即可。

  （致谢部分切勿照搬，本部分内容也在论文查重范围之内）

  （格式：宋体，Times New Roman小四号字，两边对齐，首行缩进2个字符，行距23磅，字符间距为“标准”）

]

#under-cover()
