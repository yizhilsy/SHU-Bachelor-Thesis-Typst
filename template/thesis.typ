#import "../lib.typ": documentclass, algox, tablex

#let (
  info,
  doc,
  cover,
  declare,
  appendix,
  outline,
  mainmatter,
  conclusion,
  abstract,
  bib,
  acknowledgement,
  under-cover,
) = documentclass(
  info: (
    title: "多模态表征的非线形相关性研究",
    school: "计算机工程与科学学院",
    major: "计算机科学与技术",
    student_id: "21121889",
    name: "陆诗雨",
    supervisor: "王含章",
    date: "2024.12-2025.5",
  ),
)

#show: doc
#cover()
#declare()

#abstract(
  keywords: ("多模态模型", "非线形相关性", "模态融合", "评估模态对齐"),
  keywords-en: ("MultiModal Model", "Nolinear Correlation", "Modality Interface", "Representation Alignment"),
)[
  摘要的内容需作者简要介绍本论文的主要内容主要为本人所完成的工作和创新点。

  ……

  (注：标题黑体小二号，正文宋体小四，行距20磅)
][
  The content of the abstract requires the author to briefly introduce the main content of this paper, mainly for my work and innovation.

  …….

  (Times New Roman，小四号，行距20磅)
]

#outline()

#show: mainmatter
= 绪论

== 研究背景及意义
在人类社会及科技发展的过程中，对于多个模态信息的呈现、处理和理解需求一直存在。早期人们希望可以实现多媒体传播来传递例如视频、图像、文本等信息，这促进了互联网技术和多媒体技术的发展。随着近年来人工智能技术的快速发展，人们希望构建一种通用的智能体来处理并帮助理解多个模态之间的信息，例如根据输入的描述从视频中提取关键帧，根据上传的图像及问题生成相应的回答，亦或是根据描述快速地从海量数据中检索出感兴趣的图像等。这促进了人们对于多模态研究的关注程度，多模态研究的重要程度在于提供了一种高效准确的多信息处理方式以及构建通用人工智能的能力，这也是人工智能发展的核心愿景。

早期研究者设计的多模态模型主要适用于特定领域的任务，例如图文检索，图片字幕描述，视觉语言问答等任务，以这些任务为代表涌现了一批优秀的多模态模型，例如Stacked Cross Attention @lee2018stacked，Neural Image Caption @vinyals2015show，Multimodal Compact Bilinear Pooling @fukui2016mcb 等模型。然而这些模型在设计和训练时往往引入了特定任务的限定，使得模型的能力仅能专注于特定的任务，对于其他的任务适应能力差。这使得多模态领域的技术局限在有限的应用场景中，并催发人们致力于构建一个统一的泛化能力强的多模态模型的强烈兴趣。

近年来随着算力的提升和数据集数量的增加，模型朝着大规模的方向发展。通过扩展模型参数量和训练数据量，在大型语言模型（LLM）和大型视觉模型（LVM）领域有了显著的进展。大型语言模型在文本生成（Text Generation），文本理解（In-Context Learning），指令跟随(Instruct Following)等任务上的能力呈现出了优异的水平；大型视觉模型在目标检测（Object Detection），图像分割（Image Segmentation），图像分类（Image Classification）等任务上也表现出了令人印象深刻的性能。随着大模型在各自模态中的成功，研究者们开始关注在多模态领域中的进一步研究，多模态模型的正式定义是指*具有同时处理和理解多种模态（如文本、图像等模态）的信息的能力，并且进一步可以完成多模态任务如图文检索（Iamge-Text Retrieval），视觉问答（Visual Qusetion Answer）的模型*。大型语言模型在指令跟随及文本理解上的强大性能显示了文本作为通用任务指令的接口的可行性，借助预训练大型语言模型出色的零样本及少样本能力，可以帮助模型更好地建模不同模态间的语义关联，因此研究者们开始关注以大型语言模型为基础的多模态模型的研究。一个直接且作为当前主流的思路是应用在各自模态中取得显著性能的大模型，*然而，如何有效地将不同模态的信息进行融合并且让多模态模型准确地理解来自不同模态的信息来完成多模态任务是多模态领域中的关键问题*。

研究者们在近年来提出了多种基于大型语言模型的多模态模型以及相关的多模态融合方法。值得注意的是，无论是在设计多模态模型的网络还是在设计多模态模型的预训练任务上，研究者们都强调了多模态对齐的重要性。在ALBEF @li2021alignfusevisionlanguage 的工作中，研究者从理论分析出发，借助多模态互信息下限最大化的角度揭示了模态对齐的价值和重要性。同样的，ALBEF在网络设计上也引入了图文对比学习的网络来实现模态对齐的目标。类似的，在LLaVA @llava 的工作中，研究者将训练步骤拆分为了两个阶段，第一阶段在大量的图文描述对上进行训练，目标也是模态对齐。

然而，虽然研究者们都肯定了多模态大模型模态对齐的价值，但现有的研究未针对模态对齐融合的质量进行详细的研究，研究者们往往通过经验的方式或是设计相关的预训练任务（如图文对比学习任务等）来粗略地考虑是否对齐，*缺乏一个客观的易于计算的评估指标来反映模型在训练阶段时不同时刻模态对齐融合的质量*，从而指导模态对齐融合网络的训练，设计并以此提升模态对齐融合的质量和多模态大语言模型在下游任务上的性能。

在深度神经网络的可解释性领域，为了衡量两个神经网络是否相似，研究者们借助计算由两个神经网络产生的不同数据潜在表征之间的统计相关性来衡量相似性 @nguyen2021do 。本文受到这种方法的启发，通过计算不同模态的数据（主要是图像-文本对的数据）在多模态大语言模型中产生的数据表征间的统计相关性来衡量多模态大语言模型的模态对齐程度（能力）。然而这些多模态表征在如今的多模态大模型中不仅是高维的，且互相存在复杂的非线形关系，利用传统的线形相关性及非线形相关性计算方法如CCA @cca ， SVCCA @svcca ， CKA @cka ，dCor @dcor1 @dcor2 等都不能准确有效地衡量相关性。幸运的是，最近在idcor @basile2024intrinsic 的工作中提出的idcor计算指标在衡量表征之间的相关性上表现出了远超传统方法的性能， 尤其是在多模态表征领域。它利用了归一化互信息，但使用了表征的本征维度来代替表征的熵，使用低维数据集中可以恢复的在高维数据集中自变量的比例衡量了相关性。由于idcor衡量指标在多模态表征上的出色表现，本文基于idcor指标，提出了可以用于评估多模态大模型的模态对齐质量的评估算法，且提出了可适用于庞大评估模态对齐数据集的分组计算期望算法。并在近年来主流的开源多模态大模型上进行了实验验证证明其合理性。

本文希望本文提出的多模态表征的非线性相关性评估算法可以帮助更准确严谨地衡量多模态大模型模态对齐的性能。此外本文也注意到多模态表征的非线性相关性指标可以进一步帮助模态对齐融合网络的设计与训练过程，并有助于多模态大语言模型在下游任务上微调后的性能；同时多模态表征的非线性相关性指标还有可能有助于构建高质量多模态数据集。本文也针对多模态表征的非线形相关性指标可能带来的应用进行了比较详实的实验探索。本文的研究以期进一步推动多模态大语言模型的发展。

== 相关研究现状

=== 多模态模型的模态融合方式发展历程

在多模态领域的研究历史中，研究者们倾向于首先为每个模态选取一个表现优异的单模态模型，这些单模态模型往往是预训练好的，而将研究的主要工作放在设计不同种模态表征之间的融合方式上。多模态领域的早期工作中，融合不同模态的表征采取了简单直接的方式 @vinyals2015show @Lu2015。以视觉-语言的多模态模型为例，在Neural Image Caption @vinyals2015show 的工作中，图像表征由图像在卷积神经网络（CNN）的最后一层隐藏层得到，并直接送入循环神经网络（RNN）的decoder中进行图像描述生成；在Deeper LSTM and normalized CNN @Lu2015 的工作中，对由卷积神经网络得到的图像嵌入向量和由长短期记忆网络（LSTM）得到的问题文本的嵌入向量进行逐点相乘，得到一个新的向量作为图像和文本的融合表征并在之后送入多层分类器去预测词语的概率分布。简单直接的模态表征融合无法捕捉不同模态表征间深层次的语义关系，且受限于早期的单模态模型的性能，这些方法的性能有限，同时模型往往是为了特定的任务而设计并训练的，缺乏泛化到多种任务上的能力。

之后的研究随着新的优秀的单模态模型的提出，尤其是在目标检测领域及自然语言处理领域取得成功的模型，同时随着注意力机制 @vaswani2017attention 及多模态领域中交叉注意力机制理论@NEURIPS2019_c74d97b0 的成熟与推广，研究者们基于新的单模态模型提出了更为复杂的基于注意力机制的模态融合方法。例如在LXMERT @tan2019lxmertlearningcrossmodalityencoder 的工作中，图像模态的表征由目标检测模型检测到的物体的区域感兴趣特征及位置信息特征得到，并在之后与文本模态的表征进行交叉注意力机制的融合。然而，这种模态融合方法并没有将不同模态的表征映射进同一个维度空间中进行融合，这对于模型捕获到不同模态表征间的语义关联造成了阻碍；同时目标检测的视觉模型在预训练和推理时的计算资源消耗较大 @li2021alignfusevisionlanguage。

近年来大型语言模型在自然语言处理领域中取得了一系列成功，如：ChatGPT @ChatGPT 和GPT-4 @GPT4 等模型，大型语言模型为研究者展现了其卓越的指令跟随及文本理解能力。得益于预训练大型语言模型的开源，如LLaMA @touvron2023llamaopenefficientfoundation
 , Vicuna @vicuna2023 , Qwen @bai2023qwentechnicalreport 等，使得在多模态研究中构建以大型语言模型为中心的多模态模型成为可能。这是因为可以利用文本作为通用任务指令的接口得以让模型可以训练并理解多种不同的复杂任务，同时借助预训练大型语言模型出色的语言理解和指令跟随能力，这使得构建通用的可以泛化到多种不同多模态任务的模型变成了可能。目前，以大模型为基础的多模态模型主要有三种模态融合的方式：分别是以LLaVA @llava 为代表的直接投影法，以BLIP-2 @blip2 为代表的基于Attention架构的Q-Former方法，以及以Flamingo @flamingo 为代表的在大型语言模型内部插入额外参数模块以实现文本特征和视觉特征的交互融合，从而将视觉信息注入到文本的生成过程中的特征极板块融合法。

从多模态模型的发展历程中可以看出，多模态模型的研究重点主要在于模态融合的方式上。值得提出的是，近年来以大型预训练语言模型为中心的多模态大模型的研究倾向于冻结部分或全部视觉模型和文本模型的参数，专注于训练模态融合的网络参数；同时在大型语言模型的指令微调技术也应用到了多模态大模型当中 @llava @instructblip 。模态融合方式直接影响了多模态模型能否建模不同模态间复杂的语义，进一步呼吁了设计合理高效的模态融合网络及评估算法的需求。

=== 现有评估多模态模型多模态对齐程度的方法
近年来的研究中，研究者们从多种角度出发提出了评估多模态模型模态对齐程度的方法。对表征集合中的数据点进行降维并绘制降维后在二维或三维空间中的数据点散点图是一种常用的可视化角度的评估多模态对齐的方法。

1. PCA方法

2. t-SNE方法

3. UMAP方法

=== 潜在空间表征相关性衡量指标研究现状
在神经网络的可解释性领域，一个研究的关键点是试图判断两个不同的神经网络是否可以在相同的数据集上学习到相似的方式去处理数据。虽然定义两个神经网络具有相似的行为存在一定的困难和歧义，但在最近几年研究者们从神经网络学习到的表征之间的统计相关性入手，取得了重大的进展。基于表征学习和统计相关性，研究者们已经提出了许多线形及非线形的可用于衡量表征间相关性的指标，如Singular Value Canonical Correlation Analysis (SVCCA) @svcca ，Centered Kernel Alignment （CKA） @cka，Distance Correlation（dCor）@dcor1 @dcor2，Canonical Correlation Analysis（CCA） @cca 等。这些技术已被广泛用于更深入地了解神经模型处理信息方式的各个方面。

然而，上述指标存在一些局限性。例如Canonical Correlation Analysis（CCA）主要从线形相关的角度出发去衡量表征之间的相关性，但在实际情况下，不同的表征之间往往存在复杂的非线形关系；从表征的数据点之间的距离出发的Distance Correlation（dCor）指标虽然能够捕获一定的非线形关系，但是在高维的表征上表现不佳 @basile2024intrinsic；从硬件要求的角度出发，Centered Kernel Alignment （CKA）在计算大规模数据集上得到的表征时需要消耗过高的显存及计算资源，且计算复杂度较高。在如今的多模态模型朝着大规模，使用大型语言模型的趋势下，现有的表征相关性指标在衡量多模态大模型产生的大量高维，彼此间由不同模态的模型产生的表征时的性能不甚理想。

在最近的研究中，Lorenzo @basile2024intrinsic 等人提出了一种新的衡量表征之间的相关性的方法，称为Intrinsic Distance Correlation（idcor）。该方法使用了归一化互信息，但使用了表征的本征维度来代替表征的熵，并使用低维数据集中可以恢复的在高维数据集中自变量的比例来衡量相关性。该指标在高维非线形的表征上相比之前的几种指标表现出了更好的性能，此外在多模态数据集上也具有强大的能力去衡量不同模态的模型产生的表征之间的相关性（例如图文模型在MSCOCO @mscoco2014 数据集上产生的表征之间的相关性），相比原先的基线指标dCor具有大幅的性能领先。同时，idcor指标的计算代价主要来自计算表征集合的本征维度。而运用TwoNN @twoNN 来计算本征维度已被大量的工作证实具有高效性 @NEURIPS2019_cfcce062 ，且TwoNN在大规模数据上的表征点的高维空间密度高度不均匀时也能表现出良好的性能。因此idcor指标的计算资源代价也是优秀的。

然而，在Intrinsic Distance Correlation（IdCor） 的工作中却尚未将此指标应用于近年来主流的开源多模态大模型产生的不同模态的表征评估上，仅针对一些早期的视觉及文本模态模型如ResNet-18 @resnet ，EfficientNet @efficientnet ， VIT @vit ，Bert @bert ，ALBERT @albert ，Electra @electra 及CLIP @clip 下属的单模态模型上进行了多模态表征相关性的实验 @basile2024intrinsic 。虽然这些单模态模型常被用作构建多模态大模型的模态编码器，但在如今多模态大模型火热发展的趋势下所造成的贡献较为局限。这也是本文的研究动机之一。本文希望借助idcor指标的优越性能，设计出一个可以用于评估多模态大模型模态对齐质量的高效评估算法，并在主流的多模态大模型上进行实验验证。

=== 多模态潜在空间对齐的理论研究现状
在Luca Moschella @moschellarelative 等人的工作中经验性地揭示了如果多模态的数据存在某种语义对齐（例如图像及其对应的描述），那么就可以在潜在空间中传递知识。这种知识传递的可行性由原始表征的每个点与一组固定的锚点之间的距离所代表的相对表征来实现。Luca Moschella等人还表明使用这种相对表征，可以不需要额外训练的情况下，将来自不同模态的模型的编码器和解码器拼接在一起 @basile2024intrinsic。

同时也有研究表明 @pmlr-v202-moayeri23a ，当对对齐数据（即相同的数据或共享某些语义的多模态数据，例如图像-标题对）进行评估时，大型最先进的视觉和文本编码器可以产生可转移的表示。事实上，一个简单的线性变换通常就足以将一个潜在空间映射到另一个潜在空间。从而实现借助另一个模态的表征来完成对应的下游任务例如分类等。

在语义对齐的多模态数据上存在的多模态潜在空间的相关性可以用于建模不同模态间深层次的语义关系。如果存在一个不依赖任何下游任务评估的情况下检测这些相关性的指标，那么可以用于帮助研究者衡量模型模态对齐程度，以便及时做出调整更好的让模型建模不同模态之间的语义。

== 本课题的研究难点
1. 研究难点一：在多模态大语言模型中的多模态表征往往具有高维，强非线形等特点，如何寻找一个客观合理的指标衡量多模态表征的相关性将是一个难点。同时，高维往往代表着计算复杂度的庞大，如何有效控制时间复杂度及计算资源的消耗也是一个必须考虑的难点。

2. 研究难点二：多模态大语言模型的训练涉及多个阶段且不同的阶段会更新不同模态模型的参数，这导致了复杂的训练流程。其中准确理解其训练流程并优雅合理地编写对应的代码将会是一个令人兴奋的挑战。

3. 研究难点三：现有的数据表征相关性研究大多立足于数据本身，而多模态表征的非线性相关性指标如何有效地用于衡量多模态大语言模型的模态对齐融合程度需要设计合理的评估算法并充分分析评估算法的鲁棒性，且需要权衡评估算法在计算资源上的消耗。这将是一个可能的挑战。


== 本文研究内容
在多模态领域的研究中，设计一个高效的模态融合网络一直是一个重要的研究方向。在很多研究者的工作中，如Junnan Li @li2021alignfusevisionlanguage @blip2， Haotian Liu @llava 等人，都从模态融合网络的设计或是多模态预训练任务的角度上出发来保证模态融合网络的模态对齐性能。在一些研究中，如Haotian Liu @llava 等人通过消融的实验方式证实了缺乏模态对齐的训练步骤会对多模态模型的性能造成显著的下降。尽管现有的研究都在关注模态对齐的重要性，但现有的研究往往缺乏一个客观的评估指标来衡量模态对齐的质量亦或是观察多模态模型在训练过程中模态对齐程度的变化。研究者们同样也只能从多模态模型在下游任务上的性能来间接地推测设计的模态融合网络是否合理。并不利于多模态模型的进一步设计与优化。

针对以上提到的这些问题，本文的研究内容如下：
1. 研究内容一：介绍现有的主流多模态大语言模型的设计架构（如BLIP-2 @blip2，LLaVA @llava，Flamingo @flamingo 等），理解分析主流架构在模型设计尤其是多模态表征对齐融合网络设计上的思路并捋清发展历程，分析各种多模态表征对齐融合网络的优劣和特点。

2. 研究内容二：研究多模态表征的非线性相关性，提出一个客观准确的，计算高效的评估相关性算法，并通过多角度的实验（如在高维、强非线形、线形数据集、现实多模态数据集上验证）与其他计算多模态表征的相关性的指标进行对比，分析其优劣，得到一个最佳的计算多模态表征之间的非线性相关性的算法。

3. 研究内容三：借助研究内容二得到的指标衡量不同的多模态大语言模型（可能是不同的多模态大语言模型也可能是同一个多模态大语言模型的不同训练阶段）在模态对齐上的程度。设计实验研究模态对齐融合的程度将如何影响模型在后续下游任务上的性能。下游任务上的性能将借助现有的研究广泛采用的一些benchmark基准测试，如ScienceQA @scienceqa ，VQAv2 @vqav2 等来进行评估。

4. 研究内容四：初步探索如何借助研究内容二得到的指标指导模态对齐融合网络的设计，训练及过滤高质量多模态数据集。

== 本文组织架构
之后再写吧

= 多模态相关技术介绍
本章的目的是进行多模态领域的重要技术的简要介绍。本章的前半部分将主要介绍如Transformer、多模态对比学习、多模态融合网络等技术，便于后续章节如IdCor指标的分析提供背景及理论依据；本章的后半部分将简要介绍多模态领域中所常用的一些开源数据集及benchmark评估任务，便于后续章节实验设计的背景介绍。

== Transformer


#figure(
  image(
    "figures/transformer.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [直接投影法的多模态大语言模型], // 英文图例
)<transformers>

#v(1.5em)




=== 注意力机制

=== 位置编码

=== 编码器-解码器

== 多模态对比学习
对比学习是一种无监督学习方法，旨在通过对比样本之间的相似性和差异性来学习有效的表征。对比学习的核心思想是将相似的样本拉近，而将不相似的样本推远，从而使得模型能够更好地理解数据的结构和特征。
#figure(
  image(
    "figures/clip_contrastive.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [多模态对比学习（以CLIP为例）], // 英文图例
)<clip_contrastive>

#v(1.5em)



== 大型语言模型结构及开源LLM

=== LLaMA
LLaMA是Meta AI于2023年发布的一种大型语言模型，具有7B、13B、30B和65B四个参数规模的版本。LLaMA模型在多个自然语言处理任务上表现出色，并且在一些基准测试中超过了GPT-3和GPT-4等其他大型语言模型。

=== Vicuna
Vicuna是一个开源的对话模型，基于LLaMA模型进行微调。它在多个对话任务上表现出色，并且在一些基准测试中超过了GPT-3.5等其他大型语言模型。

=== Qwen


== 多模态大语言模型网络结构

=== BLIP-2
#figure(
  image(
    "figures/qformermllm.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [单层Q-Former注意力机制的多模态大语言模型], // 英文图例
)<qformermllm>

#v(1.5em)


=== LLaVA

#figure(
  image(
    "figures/mlpmllm.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [直接投影法的多模态大语言模型], // 英文图例
)<mlpmllm>

#v(1.5em)

=== Flamingo
#figure(
  image(
    "figures/flamingomllm.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [特征级融合板块的多模态大语言模型], // 英文图例
)<flamingomllm>

#v(1.5em)

== 开源多模态数据集

=== MSCOCO

=== N24News

== 常用的多模态benchmark评估任务

=== VQAv2
#figure(
  image(
    "figures/vqav2.png",
    width: 100%,
  ),
  kind: "image",
  supplement: [图],
  caption: [VQAv2 Benchmark], // 英文图例
)<vqav2info>

#v(1.5em)

=== ScienceQA
#figure(
  image(
    "figures/scienceqa.png",
    width: 100%,
  ),
  kind: "image",
  supplement: [图],
  caption: [VQAv2 Benchmark], // 英文图例
)<scienceqainfo>

#v(1.5em)



=== TextVQA


== 本章小结
通过本章节对多模态技术的简要介绍，本章节对于多模态领域的重要技术做了一个简明直接的回顾，并对于多模态对齐融合网络中的模态对齐方式提供了背景知识，为后续章节的内容提供了必要的背景知识。


= 评估多模态大型语言模型模态融合程度的算法

== 问题分析
已经有相当多的工作肯定了在多模态模型中，模态融合网络确保模态对齐对于模型在下游任务上的性能的重要性 @llava @li2021alignfusevisionlanguage ，模态对齐的质量直接影响了模型在下游任务上的性能。但现有的研究中缺乏一个客观的评估指标来衡量多模态模型在训练时模态对齐程度的变化。因此对于模型模态对齐的质量的评估处于一种黑盒状态，这将影响多模态模型模态融合网络的设计与在下游任务上的性能。

本文认为，从多模态模型经过模态融合网络后产生的各模态表征的角度出发，计算各模态表征之间的统计相关性可以作为评估模态对齐程度的切入点。从神经网络学习到的表征出发，如果两个表征集合存在较高的统计相关性，则表明这两个神经网络学习到了类似的表征表示，这两个神经网络可以以相似的方式处理数据。从多模态的角度来解释，如果多模态表征之间的相关性程度较高，这表明模态融合网络在训练的过程中成功地学习到了一个多模态对齐的表征空间，各模态的知识可以有效地进行传递 @moschellarelative ；反之，如果模态表征之间的相关性程度较低，则表明模态融合网络未能学习到一个足以有效对齐多模态表征的表征空间，各模态表征还是处于各自的模态空间中且各模态的知识也未能有效地传递。

然而，由于各模态的模型产生的表征往往具有高维，互相之间强非线形的特点，对于计算表征相关性的指标适应高维和捕获非线形相关性的能力提出了挑战。例如在CLIP @clip 的工作中，使用了ViT-L/14\@336px @vit 作为视觉模型的骨干，其产生的视觉表征为1024维；同时对于文本模型的骨干，使用了12个768维的Transformer层@vaswani2017attention ， 这反映了由多模态模型产生的表征高维的特点。同时由于多模态表征在初始时是由不同模态的单模态模型产生的，表征可能仍处于各自模态的维度空间中，因此不同模态表征的维数也可能并不一致，这反映出了非线形的特点。此外，随着近年来多模态模型朝着以大型语言模型为中心的趋势发展（例如，LLaMA模型的嵌入层为4096维），进一步加剧了多模态表征的高维特点。

因此，一个合理的评估多模态表征之间的相关性必须保证其对于高维空间的适应性及突出的非线形相关性捕获能力。在本章节的剩余部分将在人造数据表征、神经网络表征、单一模态（视觉）表征、多模态（图文）表征角度上进行多种衡量表征相关性指标的充分对比实验。此外还将基于衡量表征相关性的指标设计一个评估多模态大型语言模型模态对齐程度的算法。

== 研究思路与问题构建
为了解决多模态模型产生的表征之间的相关性评估问题，本文首先搜集了之前的研究中提出的多种衡量表征之间的统计相关性的指标，这些指标大多是在深度神经网络的可解释领域中研究并提出的 @klabunde2023similarity。例如：典型相关性分析（CCA） @cca ，奇异值分解典型相关性分析（SVCCA）@svcca ，中心化核对齐 （CKA） @cka ，投影加权典型相关性分析（PWCCA） @pwcca ， 距离相关系数（dCor） @dcor1 @dcor2 等，此外还有本文重点探讨的本征维度相关系数（IdCor） @basile2024intrinsic 。

为了充分地对比这些指标在多种条件下计算数据表征相关性的能力，本文设计了多种条件下的实验来对比这些指标的性能，具体来说，总共有四种实验条件，分别是：人造数据表征、神经网络表征、单一模态（视觉）表征、多模态（图文）表征。若我们记此时使用的评估指标、第一个表征矩阵、第二个表征矩阵、计算得到的相关性分别为 $Theta, X in RR^(n times d_1), Y in RR^(n times d_2), sigma$，那么我们将得到如下的计算公式:
$ sigma = Theta(X_(n times d_1), Y_(n times d_2)) \
Theta in \s\e\t{\m\e\t\r\i\c\s} quad sigma in [0,1]
$<corrcomputation>

在四种实验条件下得到两个表征的矩阵$X_(n times d_1) 和 Y_(n times d_2)$  后，再依据@eqt:corrcomputation 便可以应用多种指标来计算这两个表征矩阵之间的相关性。需要指出的是，由于一些指标的实现算法需要消耗大量的显存/内存，例如中心化核对齐（CKA），合理地选取表征矩阵的行大小$n$（即表征数量）是重要的。

为了实现衡量多模态大型语言模型模态融合程度的目的，在通过对比实验得到一个良好的评估多模态表征相关性的指标后，还需要再根据几类多模态大型语言模型模态融合网络的特点，基于之前对比出来的良好的评估多模态表征相关性的指标去设计评估多模态大型语言模型模态对齐程度的算法。这个评估算法将考虑到实际的庞大评估数据集的计算资源消耗问题与多模态大型语言模型产生的表征的抽取及融合问题。

== 衡量表征相关性的基线指标的原理
在本小节中将主要阐述上文中提到的一些衡量表征相关性的基线指标的原理。

这个之后再写


== 本征维度（Intrinsic Dimension）及估算算法
本小节将主要介绍本征维度（Intrinsic Dimension）的原理、应用及估算算法，为后续3.5节介绍IdCor指标的原理提供必要的背景知识。

本征维度最早出现在统计学的数据降维领域。高维数据集通常具有复杂的结构和特征，直接处理这些数据可能会导致计算效率低下和信息丢失。数据降维的原理是将高维数据集中的数据点投影到一个低维空间中，以便更好地理解和分析数据并简化数据的表示和处理。研究者们试图通过对高维离散数据集合的分析，来找寻嵌入在高维数据空间的本征低维流型，其包含了数据的绝大部分信息，以实现数据集降维的目的。大多数的研究者都将本征低维流型的维度视为本征维度。

本征维度的正式定义是指*一个数据集的实际有效维度的数量，即可以用最少的维度来表达数据集的大部分信息。*如@img:2dimension_corr 所示，呈现了三类二维数据集合，第一维$X$与第二维$Y$的关系分别是：线形相关（$X=Y$）、螺线关系（$X=theta/(6pi)cos theta，Y=theta/(6pi)sin theta，theta in [0，6pi]$）、随机采样关系（正态分布，$f(x)=1/(sqrt(2pi)sigma)e^(-(x-mu)^2/(2sigma^2))，f(y)=1/(sqrt(2pi)sigma)e^(-(y-mu)^2/(2sigma^2))$） ，每类数据集合采样为5000个数据点。不难观察到，第一类数据集合到本征维度为1，因为可以用一个变量来代表另外一个变量；第二类数据集合的本征维度为1，因为螺线关系采样出来的数据集本质上可以用一个极坐标函数$r=r(theta)$表示，也只需要一个变量$theta$来表示另外一个变量；而第三类数据集合的本征维度为2，因为两个变量之间没有任何关系，且两个变量均服从独立的正态分布，因此采样的数据集合需要两个变量（坐标）来表示。从这个简单的例子中，可以反映本征维度的定义，即原始的数据集合中存在冗余的无效的维度，去除那些冗余的无效的维度后，就是这个数据集合的本征维度。

#figure(
  image(
    "figures/2dimension_corr.png",
    width: 90%,
  ),
  kind: "image",
  supplement: [图],
  caption: [三类二维数据集合的本征维度], // 英文图例
)<2dimension_corr>

#v(1.5em)

对于本征维度的估算，已经有大量的研究对于计算一个数据集的本征维度提出了许多具有优异性能的方法，例如主成分分析法（PCA），Facco @twoNN 等人提出的TwoNN，Elizaveta @mle 等人提出的MLE等方法。
1. 主成分分析法通过寻找数据集中的主成分来减少数据的维度，基本思想是通过线性变换将数据投影到一个新的坐标系中，使得投影后的数据在新坐标系中的方差最大化，从而保留数据的主要特征，但这种方法在处理非线形数据流型时会因为依赖于线形变化而受限。
2. TwoNN方法的核心思想是：利用每个点的最近两个邻居之间的距离比值分布来估算本征维度。若我们记点$p$距离其最近二邻的欧几里得距离分别为$r_1$和$r_2$，那么借助 @eqt:neighbour_rate_twonn 可以计算得到它们之间的比例。需要注意的是，TwoNN假设数据点均匀分布在一个 $d$ 维流形上，因此$mu$满足帕累托分布$\P\a(d+1)$，其中 $d$ 代表了数据集的本征维度。因此可以通过 @eqt:twonn_pareto 来计算给定的 $N$ 个样本点的分布在本征维度为 $d$ 时的条件概率。进而，我们可以通过线形回归来求解本征维度 $d$。

$
  mu = r_1 / r_2
$<neighbour_rate_twonn>

$
  P(mu|d)=d^(N) product_(i=1)^(N) mu_i^(-d-1)
$<twonn_pareto>

3. MLE的核心思想是：基于假设数据在某个低维流形上近似均匀分布，使用局部点之间的距离分布构建似然函数，从而估算该流形的维度。该方法假设了数据点在一个 $d$ 维欧几里得空间中的小邻域内均匀分布，对每个点 $x$，取它的 $k$ 个最近邻点$x_(1), x_(2), ..., x_(k)$。假设这些点构成一个 $d$ 维球体内的样本，点之间的距离 $r_(1), r_(2), ..., r_(k)$ 可看作从一个半径为 R 的球体中随机抽取的。以这些距离为数据构建出维度 $d$ 的最大似然估计，推导出的无偏估计公式如 @eqt:mle1 所示。再将所有数据点的 $hat(d)(x)$ 平均起来，得到整个数据集的本征维度估计 $hat(d)$ ，如@eqt:mle2 所示。

$
  hat(d)(x) = [1/(k-1)sum_(i=1)^(k-1)log(r_k/r_i)]^(-1)
$<mle1>

$
  hat(d) = 1/N sum_(x in X)hat(d)(x)
$<mle2>

通过仅依赖来自最近邻的本地信息，TwoNN方法不需要对数据的几何属性或密度进行详细假设，并且在应用于高维数据集时（$>=10^4$）TwoNN方法显得更直接且不易出错， 此外其计算的时间及空间复杂度为 $O(N^2)$ ，其中 $N$ 为给定的样本点的数，这表明其优异的计算资源开销。在Alessio @NEURIPS2019_cfcce062，Lorenzo @basile2024intrinsic 等人的工作中也通过实验验证了TwoNN算法的优点。本文之后的工作将主要建立在高维多模态表征中，因此TwoNN是本文选取的用于计算本征维度的方法。

== $\I_d\C\o\r$指标原理介绍
本小节将对Lorenzo等人提出的$\I_d\C\o\r$指标及相关理论公式进行详实的介绍。$\I_d\C\o\r$指标从信息论中的归一化互信息（Normalized Mutual Information - NMI）角度出发，并借助本征维度来简化了互信息中所需的熵的计算。

如果有两个数据集合$X in RR^(n times d_1)，Y in RR^(n times d_2) $，如果想量化它们之间的相关性，归一化互信息是量化同时采样的随机变量之间关系的基本指标，其计算公式如@eqt:mutualinfo 所示 @horibe1985entropy 。但是由于“维度诅咒”的影响，在高维的数据集合中，互信息直接从选定的数据样本集合$X$和$Y$中计算具有挑战性，因为归一化互信息@eqt:mutualinfo 的计算需要计算熵$H(X)$和$H(Y)$，而在高维空间中，数据会迅速变得稀疏，几乎填不满空间，这会使得熵的估计变得不可靠。

$
  rho.alt = I(X, Y) / ( \m\a\x(H(X), H(Y)) ) = (H(X) + H(Y) - H(X, Y)) / ( \m\a\x(H(X), H(Y)) )
$<mutualinfo>

之前的研究工作中，有研究者证明可以使用数据集合的本征维度代替数据集熵的计算，因为本征维度拥有大部分熵的特性，并且在大规模数据集中本征维度的计算更简单迅速。Lorenzo等人通过引入数据集的本征维度来代替数据集的熵的计算，进而简化归一化互信息的计算，且将数据集合的本征维度与数据集合之间的相关性联系起来。简化后的公式便称为$\I_d\C\o\r$指标的计算公式。$\I_d\C\o\r$指标的计算公式如@eqt:idcor 所示。

$
  \I_d\C\o\r(X, Y) = (\I_d (X) + \I_d (Y) - \I_d (X plus.circle Y)) / (max(\I_d (X), \I_d (Y)))
$<idcor>

$X plus.circle Y$表示将$X$数据集合与$Y$数据集合按每个数据点的维数拼接。此外，值得注意的是，不管使用哪种估计数据集合的本征维度的方法，都存在可能的误差。因此可能计算出并不准确的本征维度$I_d$值，进而影响到$\I_d\C\o\r$指标的可信。因此，Lorenzo等人利用了置换检验的思想，引入了一个置信指数$p$来辅助计算两个数据集合之间的相关程度。置信指数$p$代表着两个数据集合之间不相关的假设成立的概率。其思想是针对按照维度拼接的数据集合$X plus.circle Y$，人为进行总计$\s\h\u\f\f\l\e\N$次的行打乱（即按行更改数据点的排列），统计总共有多少次的行打乱后，$I_d (X_i plus.circle Y_i)$小于了原始的$I_d (X plus.circle Y)$，其中$X_i，Y_i$分别为此时行打乱后的数据集合。假设统计出来的次数为$L$，那么置信指数$p$的计算公式如@eqt:idcor_pvalue 所示。

$
  p = (L + 1) / (\s\h\u\f\f\l\e\N + 1)  
$<idcor_pvalue>

置信指数$p$的值越低，表明两个数据集合之间的相关性程度越高，反之则越低。从直觉的角度来看，如果两个数据集合之间存在较高的相关性，那么进行总计$\s\h\u\f\f\l\e\N$次的行打乱后，每次的打乱使得$I_d (X_i plus.circle Y_i) < I_d (X plus.circle Y)$的概率都不大，这是因为进行行打乱会破坏原有数据集合的相关性，因此针对维度拼接的数据集合$X plus.circle Y$估算出来的本征维度倾向于增加（破坏原有的两个数据集合的相关性后，需要更多的维度来表示这两个数据集合拼接后的集合），因此统计出来的$L$并不会很大，置信指数$p$也不会很大；反之，如果两个数据集合之间本身的相关程度不高，那么进行行打乱后，可能打乱后的数据集合$X_i，Y_i$在某些维度上存在一些相关性，因此针对维度拼接的数据集合$X plus.circle Y$估算出来的本征维度倾向于减少（在某些维度上存在的相关性减少了拼接后的集合所需的本征维数），导致$I_d (X_i plus.circle Y_i) < I_d (X plus.circle Y)$的概率会增大，进而导致统计出来的$L$会较大，置信指数$p$也会较高。

@eqt:idcor 和@eqt:idcor_pvalue 计算得到的$\I_d\C\o\r$数值和置信指数$p$统一称为$\I_d\C\o\r$指标。实现$\I_d\C\o\r$指标的算法伪代码如@algo:idcoralgo 所示。一般来说，$\I_d\C\o\r$指标的值范围在$[0,1]$之间。本文之后将基于$\I_d\C\o\r$指标来高效地计算多模态大型语言模型产生的表征之间的相关性，这个指标是评估多模态大型语言模型模态融合程度的算法的基础。

#[
  #import "@preview/lovelace:0.2.0": *
  #algox(
    label-name: "idcoralgo",
    caption: [$\I_d\C\o\r$指标计算算法伪代码],
    pseudocode(
      no-number,
      [#h(-1.25em) *input:* Two matrices $X in RR^(n times d_1)$ and $Y in RR^(n times d_2)$, $I_d$ estimator algorithm id_algo, and the number of shuffles $\s\h\u\f\f\l\e\N$],
      no-number,
      [#h(-1.25em) *output:* $\I_d\C\o\r$ and $p$ metric reflect the correlation between $X$ and $Y$],
      [$\i\d_1 <- "id_algo"(X)$;],
      [$\i\d_2 <- "id_algo"(Y)$;],
      [$\i\d_C <- "id_algo"("concat"(X,Y,dim=1))$;],
      [$\I_d\C\o\r <- (\i\d_1 + \i\d_2 - \i\d_C) / (max(\i\d_1,\i\d_2))$;],
      [$L <- 0;$],
      [*for* $i in {1,2,...,\s\h\u\f\f\l\e\N}$ *do*],
      ind,
      [$Y_s = "shuffle"(Y)$;],
      [$\i\d_s [i] <- "id_algo"("concat"(X, Y_S, dim=1))$;],
      [*if* $\i\d_s [i] <= \i\d_C $ *then*],
      ind,
      [$L <- L + 1$;],
      ded,
      [*end*],
      ded,
      [*end*],
      [$p <- (L + 1) / (\s\h\u\f\f\l\e\N + 1)$;],
      [*return* $\I_d\C\o\r, p$],
    ),
  )
]

#v(1.5em)



== IdCor指标与其他指标的实验对比
本小节将运用在3.2节中提到的对比实验方法来比较多种衡量数据表征相关性的指标的性能。本小节设置了四种实验条件，分别是：人造数据表征、神经网络表征、单一模态（视觉）表征、多模态（图文）表征，以此来全面地衡量多种指标之间的性能差异，有助于我们筛选出最 state of the arts的指标。

=== 在人造的数据表征上评估-0-0

=== 在神经网络上评估

=== 在单一模态（视觉）表征上进行评估

=== 在多模态表征（图文）上进行评估

==== MSCOCO

==== N24News

== 应用IdCor指标设计多模态大模型中的模态对齐评估算法
在上文的实验中，我们已经证明了IdCor指标在多模态表征的相关性评估上具有优越的性能。接下来我们将设计一个基于IdCor指标的多模态大模型模态对齐评估算法。

=== 多模态大型语言模型生成的各模态表征的融合

=== 三级标题

......

==== 四级标题

......

== 本章小结


== 本文研究主要内容

本文......

== 本文研究意义

本文......

== 本文组织架构

本文......

= 多模态大模型模态对齐



= 格式要求


正文各章节应拟标题，每章结束后应另起一页。标题要简明扼要，不应使用标点符号。各章、节、条的层次，可以按照“1……、1.1……、1.1.1……”标识，条以下具体款项的层次依次按照“1.1.1.1”或“（1）”、“①”等标识。各学院根据实际情况，可自行规定层次格式，但学院之内建议格式统一，以清晰无误为准@liu_survey_2024。

正文是毕业论文的主体和核心部分，不同学科专业和不同的选题可以有不同的写作方式。正文一般包括以下几个方面。

== 引言或背景
引言是论文正文的开端，引言应包括毕业论文选题的背景、目的和意义；对国内外研究现状和相关领域中已有的研究成果的简要评述；介绍本项研究工作研究设想、研究方法或实验设计、理论依据或实验基础；涉及范围和预期结果等。要求言简意赅，注意不要与摘要雷同或成为摘要的注解。

== 主体
论文主体是毕业论文的主要部分，必须言之成理，论据可靠，严格遵循本学科国际通行的学术规范。在写作上要注意结构合理、层次分明、重点突出，章节标题、公式图表符号必须规范统一。论文主体的内容根据不同学科有不同的特点，一般应包括以下几个方面：
+ 毕业设计（论文）总体方案或选题的论证；
+ 毕业设计（论文）各部分的设计实现，包括实验数据的获取、数据可行性及有效性的处理与分析、各部分的设计计算等；
+ 对研究内容及成果的客观阐述，包括理论依据、创新见解、创造性成果及其改进与实际应用价值等；
+ 论文主体的所有数据必须真实可靠，自然科学论文应推理正确、结论清晰；人文和社会学科的论文应把握论点正确、论证充分、论据可靠，恰当运用系统分析和比较研究的方法进行模型或方案设计，注重实证研究和案例分析，根据分析结果提出建议和改进措施等。

== 结论
结论是毕业论文的总结，是整篇论文的归宿。应精炼、准确、完整。着重阐述自己的创造性成果及其在本研究领域中的意义、作用，还可进一步提出需要讨论的问题和建议。


= 图表格式

== 图格式
#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image>

#v(1.5em)

// 图的引用请以 img 开头
如 @img:image 所示，......

== 表格格式
// 表的引用请以 tbl 开头
我们来看 @tbl:table，

可以续表:
\
\
\

#tablex(
  ..for i in range(15) {
    ([250], [88], [5900], [1.65])
  },
  header: (
    [感应频率 #linebreak() (kHz)],
    [感应发生器功率 #linebreak() (%×80kW)],
    [工件移动速度 #linebreak() (mm/min)],
    [感应圈与零件间隙 #linebreak() (mm)],
  ),
  columns: (1fr, 1fr, 1fr, 1fr),
  colnum: 4,
  caption: [66666666],
  label-name: "table",
)


== 公式格式

// 公式的引用请以 eqt 开头
我要引用 @eqt:equation。

$ 1 / mu nabla^2 Alpha - j omega sigma Alpha - nabla(1/mu) times (nabla times Alpha) + J_0 = 0 $<equation>

== 算法格式
我要引用 @algo:algorithm

算法也可以续：
#v(10em)
#[
  #import "@preview/lovelace:0.2.0": *
  #algox(
    label-name: "algorithm",
    caption: [欧几里得辗转相除],
    pseudocode(
      no-number,
      [#h(-1.25em) *input:* integers $a$ and $b$],
      no-number,
      [#h(-1.25em) *output:* greatest common divisor of $a$ and $b$],
      [*while* $a != b$ *do*],
      ind,
      [*if* $a > b$ *then*],
      ind,
      $a <- a - b$,
      ded,
      [*else*],
      ind,
      $b <- b - a$,
      ded,
      [*end*],
      ded,
      [*end*],
      [*return* $a$],
    ),
  )
]

也可以直接插入代码：
#algox(
  label-name: "algorithm-1",
  caption: [欧几里得辗转相除C++实现],
  [
    ```cpp
    #include <bits/stdc++.h>
    using namespace std;
    int gcd(int a, int b) {
      while (a != b) {
        if (a > b) a -= b;
        else b -= a;
      }
      return a;
    }
    ```
  ],
)

== 本章小结

本章介绍了……

#conclusion[
  结论是毕业论文的总结，是整篇论文的归宿。应精炼、准确、完整。着重阐述自己的创造性成果及其在本研究领域中的意义、作用，还可进一步提出需要讨论的问题和建议。
]

// 参考文献
#bib(bibfunc: bibliography("ref.bib")) // full: false 表示只显示已引用的文献，不显示未引用的文献；true 表示显示所有文献

#show: appendix

= 附录格式

论文附录依次用大写字母“附录A、附录B、附录C……”表示，附录内的分级序号可采用“附A1、附A1.1、附A1.1.1”等表示，图、表、公式均依此类推为“图A1、表A1、式（A1）”等。包含以下内容：

（1）代码、图表、标准、手册等数据；

（2）未发表过的一手文献；

（3）公式推导与证明、调查表等；

（4）辅助性教学工具或表格；

（5）其他需要展示或说明的内容

……

（标题黑体小二号，内容Times New Roman/宋体，小四号，行距20磅）

== 测试1

#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image2>
......

=== 测试1.1

#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image3>

= 测试2
#figure(
  image(
    "figures/energy-distribution.png",
    width: 70%,
  ),
  kind: "image",
  supplement: [图],
  caption: [Energy distribution along radial], // 英文图例
)<image4>


#algox(
  label-name: "twoNNpytorch",
  caption: [twoNN估算数据集本征维度算法PyTorch实现],
  [
    ```python
    def twoNN(X,fraction=0.9,distances=False):
      if not distances:
          X=torch.cdist(X,X)
      Y=torch.topk(X, 3, dim=1, largest=False)[0]
      # clean data
      k1 = Y[:,1]
      k2 = Y[:,2]
      #remove zeros and degeneracies (k1==k2)
      old_k1=k1
      k1 = k1[old_k1!=0]
      k2 = k2[old_k1!=0]
      old_k1=k1
      k1 = k1[old_k1!=k2] 
      k2 = k2[old_k1!=k2]
      # n.of points to consider for the linear regression
      npoints = int(np.floor(len(k1)*fraction))
      # define mu and Femp
      N = len(k1)
      mu,_ = torch.sort(torch.divide(k2, k1).flatten())
      Femp = (torch.arange(1,N+1,dtype=X.dtype))/N
      # take logs (leave out the last element because 1-Femp is zero there)
      x = torch.log(mu[:-1])[0:npoints]
      y = -torch.log(1 - Femp[:-1])[0:npoints]
      # regression, on gpu if available
      y=y.to(x.device)
      slope=torch.linalg.lstsq(x.unsqueeze(-1),y.unsqueeze(-1))
      return slope.solution.squeeze()
    ```
  ],
)

......

#acknowledgement(location: "上海大学")[
  表达真情实感即可。

  （致谢部分切勿照搬，本部分内容也在论文查重范围之内）

  （格式：宋体，Times New Roman小四号字，两边对齐，首行缩进2个字符，行距23磅，字符间距为“标准”）

]

#under-cover()
